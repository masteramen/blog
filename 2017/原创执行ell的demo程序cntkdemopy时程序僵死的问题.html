<!-- build time:Sat Oct 27 2018 21:00:17 GMT+0800 (CST) --><!DOCTYPE html><html class="theme-next muse use-motion"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="description" content="OS：Ubuntu 14.04在台式机上执行ELL的demo程序 cntkDemo.py 时，可能会遇到程序僵死的问题。cntkDemo.py 这个程序会调用OpenCV，在一个GUI窗口中显示USB摄像头拍摄的实时视频流，而僵死的现象正是：执行到弹出GUI窗口显示摄像头拍摄的视频流的代码的时候，程序进入僵死状态，不能执行后续逻辑。此时，只能Ctrl+C终止掉程序。我的Ubuntu 14.04是一"><meta name="keywords" content="JAVA,面试"><meta property="og:type" content="article"><meta property="og:title" content="[原创] 执行ELL的demo程序cntkDemo.py时程序僵死的问题"><meta property="og:url" content="http://www.jfox.info/2017/原创执行ell的demo程序cntkdemopy时程序僵死的问题.html"><meta property="og:site_name" content="java面试"><meta property="og:description" content="OS：Ubuntu 14.04在台式机上执行ELL的demo程序 cntkDemo.py 时，可能会遇到程序僵死的问题。cntkDemo.py 这个程序会调用OpenCV，在一个GUI窗口中显示USB摄像头拍摄的实时视频流，而僵死的现象正是：执行到弹出GUI窗口显示摄像头拍摄的视频流的代码的时候，程序进入僵死状态，不能执行后续逻辑。此时，只能Ctrl+C终止掉程序。我的Ubuntu 14.04是一"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://www.jfox.info/2017/1372/a221a9d.png"><meta property="og:updated_time" content="2018-10-27T12:29:37.383Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="[原创] 执行ELL的demo程序cntkDemo.py时程序僵死的问题"><meta name="twitter:description" content="OS：Ubuntu 14.04在台式机上执行ELL的demo程序 cntkDemo.py 时，可能会遇到程序僵死的问题。cntkDemo.py 这个程序会调用OpenCV，在一个GUI窗口中显示USB摄像头拍摄的实时视频流，而僵死的现象正是：执行到弹出GUI窗口显示摄像头拍摄的视频流的代码的时候，程序进入僵死状态，不能执行后续逻辑。此时，只能Ctrl+C终止掉程序。我的Ubuntu 14.04是一"><meta name="twitter:image" content="http://www.jfox.info/2017/1372/a221a9d.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"5.1.4",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://www.jfox.info/2017/原创执行ell的demo程序cntkdemopy时程序僵死的问题.html"><title>[原创] 执行ELL的demo程序cntkDemo.py时程序僵死的问题 | java面试</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh_CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">java面试</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle"></p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.jfox.info/2017/原创执行ell的demo程序cntkdemopy时程序僵死的问题.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Hello"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="java面试"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">[原创] 执行ELL的demo程序cntkDemo.py时程序僵死的问题</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-01T23:57:52+08:00">2017-01-01</time></span></div></header><div class="post-body" itemprop="articleBody"><p>OS：Ubuntu 14.04</p><p>在台式机上执行ELL的demo程序 cntkDemo.py 时，可能会遇到程序僵死的问题。<br>cntkDemo.py 这个程序会调用OpenCV，在一个GUI窗口中显示USB摄像头拍摄的实时视频流，而僵死的现象正是：执行到弹出GUI窗口显示摄像头拍摄的视频流的代码的时候，程序进入僵死状态，不能执行后续逻辑。此时，只能Ctrl+C终止掉程序。<br>我的Ubuntu 14.04是一台老爷机，性能非常差，我觉得这有可能程序僵死的原因之一？我试了几次都是这样，于是我打算换一个思路来跑这个demo，不再纠结于解决窗口僵死的问题。<br>文章来源： <a href="https://www.jfox.info/go.php?url=https://www.codelast.com/">https://www.codelast.com/</a><br>先来看一下原版的 cntkDemo.py 部分代码：</p><pre><code>while (True):
    # Grab next frame
    ret, frame = cap.read()

    # Prepare the image to send to the model.
    # This involves scaling to the required input dimension and re-ordering from BGR to RGB
    data = helper.prepare_image_for_predictor(frame)

    # Get the model to classify the image, by returning a list of probabilities for the classes it can detect
    predictions = model.Predict(data)

    # Get the (at most) top 5 predictions that meet our threshold. This is returned as a list of tuples,
    # each with the text label and the prediction score.
    top5 = helper.get_top_n(predictions, 5)

    # Turn the top5 into a text string to display
    text = &quot;&quot;.join([str(element[0]) + &quot;(&quot; + str(int(100*element[1])) + &quot;%)  &quot; for element in top5])

    # Draw the text on the frame
    frameToShow = frame
    helper.draw_label(frameToShow, text)
    helper.draw_fps(frameToShow)

    # Show the new frame
    cv2.imshow(&apos;frame&apos;, frameToShow)

    # Wait for Esc key
    if cv2.waitKey(1) &amp; 0xFF == 27:
        break
</code></pre><p>这段代码的注释非常清晰，它的功能是：在一个无限循环中，不断地去抓取USB摄像头拍摄的一帧图像，然后用model预测其分类及概率，最后再把预测结果叠加显示在GUI窗口中，类似于下面这样：</p><p><img src="/2017/1372/a221a9d.png" alt=""></p><p>既然 cntkDemo.py 主要是为了测试model能不能正常跑，那么我在命令行以文字形式显示预测结果也是一样的啊，没有必要非得在GUI窗口中展示。<br>文章来源： <a href="https://www.jfox.info/go.php?url=https://www.codelast.com/">https://www.codelast.com/</a><br>于是我把程序改成了下面这样（完整程序）：</p><pre><code>import sys
import os
import numpy as np
import cv2
import time

import findEll
import cntk_to_ell
import modelHelper as mh

def get_ell_predictor(modelConfig):
    &quot;&quot;&quot;Imports a model and returns an ELL.Predictor.&quot;&quot;&quot;
    return cntk_to_ell.predictor_from_cntk_model(modelConfig.model_files[0])

def main():

    if (not os.path.exists(&apos;VGG16_ImageNet_Caffe.model&apos;)):
        print(&quot;Please download the &apos;VGG16_ImageNet_Caffe.model&apos; file, see README.md&quot;)
        sys.exit(1)

    # ModelConfig for VGG16 model from CNTK Model Gallery
    # Follow the instructions in README.md to download the model if you intend to use it.
    helper = mh.ModelHelper(&quot;VGG16ImageNet&quot;, [&quot;VGG16_ImageNet_Caffe.model&quot;], &quot;cntkVgg16ImageNetLabels.txt&quot;, scaleFactor=1.0)

    # Import the model
    model = get_ell_predictor(helper)

    # Save the model
    helper.save_ell_predictor_to_file(model, &quot;vgg16ImageNet.map&quot;)

    camera = 0
    if (len(sys.argv) &gt; 1):
        camera = int(sys.argv[1]) 

    # Start video capture device
    cap = cv2.VideoCapture(camera)

    while (True):
        print(&apos;Read a frame from camera...&apos;)
        ret, frame = cap.read()

        # Prepare the image to send to the model.
        # This involves scaling to the required input dimension and re-ordering from BGR to RGB
        data = helper.prepare_image_for_predictor(frame)

        # Get the model to classify the image, by returning a list of probabilities for the classes it can detect
        predictions = model.Predict(data)

        # Get the (at most) top 5 predictions that meet our threshold. This is returned as a list of tuples,
        # each with the text label and the prediction score.
        top5 = helper.get_top_n(predictions, 5)

        # Turn the top5 into a text string to display
        text = &quot;&quot;.join([str(element[0]) + &quot;(&quot; + str(int(100*element[1])) + &quot;%)  &quot; for element in top5])

        # Output the text on command line
        print(text)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre><p>OpenBLAS : Your OS does not support AVX instructions. OpenBLAS is using Nehalem kernels as a fallback, which may give poorer performance.</p><p>Read a frame from camera, time 1</p><p>Frame 1 saved to disk</p><p>Read a frame from camera, time 2</p><p>Frame 2 saved to disk</p><p>Read a frame from camera, time 3</p><p>Frame 3 saved to disk</p><p>Read a frame from camera, time 4</p><p>Frame 4 saved to disk</p><p>Read a frame from camera, time 5</p><p>Frame 5 saved to disk</p><p>Loading…</p><p>Selected CPU as the process wide default device.</p><p>Finished loading.</p><p>Pre-processing…</p><p>Will not process Dropout – skipping this layer as irrelevant.</p><p>Will not process Dropout – skipping this layer as irrelevant.</p><p>Will not process Combine – skipping this layer as irrelevant.</p><p>Convolution : 226x226x3 -&gt; 224x224x64 | padding 1</p><p>ReLU : 224x224x64 -&gt; 226x226x64 | padding 0</p><p>Convolution : 226x226x64 -&gt; 224x224x64 | padding 1</p><p>ReLU : 224x224x64 -&gt; 224x224x64 | padding 0</p><p>Pooling : 224x224x64 -&gt; 114x114x64 | padding 0</p><p>Convolution : 114x114x64 -&gt; 112x112x128 | padding 1</p><p>ReLU : 112x112x128 -&gt; 114x114x128 | padding 0</p><p>Convolution : 114x114x128 -&gt; 112x112x128 | padding 1</p><p>ReLU : 112x112x128 -&gt; 112x112x128 | padding 0</p><p>Pooling : 112x112x128 -&gt; 58x58x128 | padding 0</p><p>Convolution : 58x58x128 -&gt; 56x56x256 | padding 1</p><p>ReLU : 56x56x256 -&gt; 58x58x256 | padding 0</p><p>Convolution : 58x58x256 -&gt; 56x56x256 | padding 1</p><p>ReLU : 56x56x256 -&gt; 58x58x256 | padding 0</p><p>Convolution : 58x58x256 -&gt; 56x56x256 | padding 1</p><p>ReLU : 56x56x256 -&gt; 56x56x256 | padding 0</p><p>Pooling : 56x56x256 -&gt; 30x30x256 | padding 0</p><p>Convolution : 30x30x256 -&gt; 28x28x512 | padding 1</p><p>ReLU : 28x28x512 -&gt; 30x30x512 | padding 0</p><p>Convolution : 30x30x512 -&gt; 28x28x512 | padding 1</p><p>ReLU : 28x28x512 -&gt; 30x30x512 | padding 0</p><p>Convolution : 30x30x512 -&gt; 28x28x512 | padding 1</p><p>ReLU : 28x28x512 -&gt; 28x28x512 | padding 0</p><p>Pooling : 28x28x512 -&gt; 16x16x512 | padding 0</p><p>Convolution : 16x16x512 -&gt; 14x14x512 | padding 1</p><p>ReLU : 14x14x512 -&gt; 16x16x512 | padding 0</p><p>Convolution : 16x16x512 -&gt; 14x14x512 | padding 1</p><p>ReLU : 14x14x512 -&gt; 16x16x512 | padding 0</p><p>Convolution : 16x16x512 -&gt; 14x14x512 | padding 1</p><p>ReLU : 14x14x512 -&gt; 14x14x512 | padding 0</p><p>Pooling : 14x14x512 -&gt; 7x7x512 | padding 0</p><p>linear : 7x7x512 -&gt; 1x1x4096 | padding 0</p><p>ReLU : 1x1x4096 -&gt; 1x1x4096 | padding 0</p><p>linear : 1x1x4096 -&gt; 1x1x4096 | padding 0</p><p>ReLU : 1x1x4096 -&gt; 1x1x4096 | padding 0</p><p>linear : 1x1x4096 -&gt; 1x1x1000 | padding 0</p><p>Softmax : 1x1x1000 -&gt; 1x1x1000 | padding 0</p><p>Finished pre-processing.</p><p>Constructing equivalent ELL layers from CNTK…</p><p>Converting layer conv1_1: Convolution(data: Tensor[3,224,224]) -&gt; Tensor[64,224,224]</p><p>Converting layer relu1_1: ReLU(conv1_1: Tensor[64,224,224]) -&gt; Tensor[64,224,224]</p><p>Converting layer conv1_2: Convolution(relu1_1: Tensor[64,224,224]) -&gt; Tensor[64,224,224]</p><p>Converting layer relu1_2: ReLU(conv1_2: Tensor[64,224,224]) -&gt; Tensor[64,224,224]</p><p>Converting layer pool1: Pooling(relu1_2: Tensor[64,224,224]) -&gt; Tensor[64,112,112]</p><p>Converting layer conv2_1: Convolution(pool1: Tensor[64,112,112]) -&gt; Tensor[128,112,112]</p><p>Converting layer relu2_1: ReLU(conv2_1: Tensor[128,112,112]) -&gt; Tensor[128,112,112]</p><p>Converting layer conv2_2: Convolution(relu2_1: Tensor[128,112,112]) -&gt; Tensor[128,112,112]</p><p>Converting layer relu2_2: ReLU(conv2_2: Tensor[128,112,112]) -&gt; Tensor[128,112,112]</p><p>Converting layer pool2: Pooling(relu2_2: Tensor[128,112,112]) -&gt; Tensor[128,56,56]</p><p>Converting layer conv3_1: Convolution(pool2: Tensor[128,56,56]) -&gt; Tensor[256,56,56]</p><p>Converting layer relu3_1: ReLU(conv3_1: Tensor[256,56,56]) -&gt; Tensor[256,56,56]</p><p>Converting layer conv3_2: Convolution(relu3_1: Tensor[256,56,56]) -&gt; Tensor[256,56,56]</p><p>Converting layer relu3_2: ReLU(conv3_2: Tensor[256,56,56]) -&gt; Tensor[256,56,56]</p><p>Converting layer conv3_3: Convolution(relu3_2: Tensor[256,56,56]) -&gt; Tensor[256,56,56]</p><p>Converting layer relu3_3: ReLU(conv3_3: Tensor[256,56,56]) -&gt; Tensor[256,56,56]</p><p>Converting layer pool3: Pooling(relu3_3: Tensor[256,56,56]) -&gt; Tensor[256,28,28]</p><p>Converting layer conv4_1: Convolution(pool3: Tensor[256,28,28]) -&gt; Tensor[512,28,28]</p><p>Converting layer relu4_1: ReLU(conv4_1: Tensor[512,28,28]) -&gt; Tensor[512,28,28]</p><p>Converting layer conv4_2: Convolution(relu4_1: Tensor[512,28,28]) -&gt; Tensor[512,28,28]</p><p>Converting layer relu4_2: ReLU(conv4_2: Tensor[512,28,28]) -&gt; Tensor[512,28,28]</p><p>Converting layer conv4_3: Convolution(relu4_2: Tensor[512,28,28]) -&gt; Tensor[512,28,28]</p><p>Converting layer relu4_3: ReLU(conv4_3: Tensor[512,28,28]) -&gt; Tensor[512,28,28]</p><p>Converting layer pool4: Pooling(relu4_3: Tensor[512,28,28]) -&gt; Tensor[512,14,14]</p><p>Converting layer conv5_1: Convolution(pool4: Tensor[512,14,14]) -&gt; Tensor[512,14,14]</p><p>Converting layer relu5_1: ReLU(conv5_1: Tensor[512,14,14]) -&gt; Tensor[512,14,14]</p><p>Converting layer conv5_2: Convolution(relu5_1: Tensor[512,14,14]) -&gt; Tensor[512,14,14]</p><p>Converting layer relu5_2: ReLU(conv5_2: Tensor[512,14,14]) -&gt; Tensor[512,14,14]</p><p>Converting layer conv5_3: Convolution(relu5_2: Tensor[512,14,14]) -&gt; Tensor[512,14,14]</p><p>Converting layer relu5_3: ReLU(conv5_3: Tensor[512,14,14]) -&gt; Tensor[512,14,14]</p><p>Converting layer pool5: Pooling(relu5_3: Tensor[512,14,14]) -&gt; Tensor[512,7,7]</p><p>Converting layer fc6: linear(pool5: Tensor[512,7,7]) -&gt; Tensor[4096]</p><p>Converting layer relu6: ReLU(fc6: Tensor[4096]) -&gt; Tensor[4096]</p><p>Converting layer fc7: linear(drop6: Tensor[4096]) -&gt; Tensor[4096]</p><p>Converting layer relu7: ReLU(fc7: Tensor[4096]) -&gt; Tensor[4096]</p><p>Converting layer fc8: linear(drop7: Tensor[4096]) -&gt; Tensor[1000]</p><p>Converting layer prob: Softmax(fc8: Tensor[1000]) -&gt; Tensor[1000]</p><p>…Finished constructing ELL layers.</p><p>lighter, light, igniter, ignitor(28%)</p><p>lighter, light, igniter, ignitor(28%)</p><p>lighter, light, igniter, ignitor(32%)</p><p>lighter, light, igniter, ignitor(30%)</p><p>……</p></div><div style="width:300px;height:250px;float:left"><ins class="adsbygoogle" style="display:inline-block;width:300px;height:250px" data-ad-client="ca-pub-9477174171188196" data-ad-slot="4142158067"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><div style="width:300px;height:250px;float:left"><ins class="adsbygoogle" style="display:inline-block;width:300px;height:250px" data-ad-client="ca-pub-9477174171188196" data-ad-slot="5618891265"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/看透springmvc源代码分析与实践springmvc组件分析.html" rel="next" title="看透 Spring MVC 源代码分析与实践 —— Spring MVC 组件分析"><i class="fa fa-chevron-left"></i> 看透 Spring MVC 源代码分析与实践 —— Spring MVC 组件分析</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2017/lombok的简单介绍和使用方法-2.html" rel="prev" title="lombok的简单介绍和使用方法">lombok的简单介绍和使用方法 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview-wrap sidebar-panel sidebar-panel-active"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">Hello</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">1358</span> <span class="site-state-item-name">posts</span></a></div></nav></div></section></div></aside><div class="sfix"><div class="fixedme"><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-9477174171188196" data-ad-slot="9597600460" data-ad-format="auto"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></div></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">Hello</span></div><div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div><span class="post-meta-divider">|</span><div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script></body></html><!-- rebuild by neat -->